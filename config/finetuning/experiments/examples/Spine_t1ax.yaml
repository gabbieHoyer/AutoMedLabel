## Lumbar Spine MRI Finetuning Experimentation Config

# ------------------------ Finetuning ------------------------ #
experiment:
  name: "BACPAC_t1_axial_mskSAM2"
  pretrained_weights: mskSAM2
  description: "Fine-tuning ${experiment.pretrained_weights} on combined Lumbar Spine T1 Axial MRI datasets."

dataset:
  UH2-t1ax:
    config: UH2_T1ax.yaml
  UH3-t1ax:
    config: UH3_T1ax.yaml

SEED: 42
distributed: True 

datamodule:
  max_subject_set: full
  balanced: False
  bbox_shift: 0
  batch_size: 4
  num_workers: 1
  # augmentation_pipeline: 
  #   config: simple.yaml

module:
  work_dir: "work_dir/finetuning"
  # pretrain_model: "work_dir/model_weights/SAM2/sam2_hiera_tiny.pt"
  # pretrain_model: "work_dir/model_weights/SAM2/sam2_hiera_small.pt"
  pretrain_model: "work_dir/model_weights/SAM2/sam2_hiera_base_plus.pt"

  # pretrain_model: "work_dir/model_weights/MedSAM/medsam_vit_b.pth"
  #"work_dir/model_weights/SAM/sam_vit_b_01ec64.pth"
  checkpoint: "/data/mskprojects/mskSAM/users/ghoyer/AutoMedLabel2/work_dir/finetuning/mskSAM/SAM2_full_trainSubjects_sliceBalance_False_imgEnc_True_maskDec_True/Run_9/20240819-1329_finetuned_model_best_converted.pth"  # Resuming training from checkpoint

  trainable:
    prompt_encoder: False   
    image_encoder: True       
    mask_decoder: True     
    
  task_name: Spine_T1ax
  group_name: ${experiment.pretrained_weights}_${datamodule.max_subject_set}_trainSubjects_sliceBalance_${datamodule.balanced}_imgEnc_${module.trainable.image_encoder}_maskDec_${module.trainable.mask_decoder}
  # model_type: vit_b  # use for SAM and MedSAM models (based on the weights type available through META)
  # sam2_model_cfg: sam2_hiera_t.yaml
  # sam2_model_cfg: sam2_hiera_s.yaml
  sam2_model_cfg: sam2_hiera_b+.yaml

  use_wandb: True
  visualize: True

  num_epochs: 500

  optimizer:
    type: "AdamW"  
    lr: 0.0001   
    weight_decay: 0.01  

  scheduler:
    type: "CosineAnnealingWarmRestarts" 
    T_0: 10   
    T_mult: 1
    eta_min: 0.00001  

  use_amp: True     
  clip_grad: 1.0
  grad_accum: 4

  early_stopping:
    enabled: True
    patience: 10
    min_delta: 0.0001  

output_configuration:
  save_path: Run_Summaries
  viz_eval_path: ${output_configuration.save_path}/figs
  summary_file: ${experiment.name}_data_summary.csv
  logging_level: INFO 

# ------------------ Dataset Evaluation ------------------
visualizations:
  metadata_demographics:
    config: demo_splits.yaml
  # finetuned_splits: 
  #   config: finetuned_splits.yaml