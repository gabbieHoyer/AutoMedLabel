## mskSAM Dataset Pre-Processing Parameters
## Params for:
##     1. data_standardization.py: data standardization of input image and mask file
##     2. metadata_extraction.py: standardize metadata for statistics
##     3. model_prep.py: SAM compatible npy data standardization and slice-level metadata creation
##     4. prompt_prediction.py: extended functionality for choosing prompt experimentation / zeroshot inference

# ------------------ PARAMS FOR ALL ------------------
dataset:
  name: DHAL
  description: "3.0T 3D CUBE T2 shoulder dataset with scapula masks."

overwrite_existing_flag: True

# --- OUTPUT (DEFAULT): uses default folder structure when output path is not specified (see load_config())
default_output_dir: /users/user1/shoulder_pipeline
general_data_dir: ${default_output_dir}/standardized_shoulder/DHAL/shoulder/T2
     
# ------------------ INFO FOR DATA STANDARDIZATION ------------------
# Packaged MRI image and mask folder paths (can be dicom or other file type)
image_data_paths:  /shoulder/T2/DHAL_dcm_mask_data.csv
mask_data_paths: ${image_data_paths}

image_column: imgs_dcms
mask_column: scapula_dcms

image_config:
  key: 
  transforms:
  data_properties:
    finite_values: True

mask_config: 
  key: #msk
  transforms:
    dtype: np.uint8
  data_properties:
    finite_values: True
    type: int8

## details about your dataset:
mask_labels:
  0: background
  1: scapula

# --- OUTPUT (OVERRIDE DEFAULT): location to Output/locate nifti files for MRI images and masks
nifti_image_dir: ${general_data_dir}/nifti/imgs
nifti_mask_dir: ${general_data_dir}/nifti/masks

# ------------------ VISUALIZE NIFTI ------------------
nifti_fig_cfg:
  fig_type: 2D_overlay # Options: '2D_overlay', 'gif', ['2D_overlay', 'gif']
  num_figs: 1  # Number of files to randomly select and process
  slice_selection: 'with_segmentation' # 'any' 'with_segmentation'
# --- OUTPUT (OVERRIDE DEFAULT): location to save figures
  fig_path: ${general_output_dir}/nifti/figs

# ------------------ INFO FOR SAM PREP ------------------
## SAM compatible npy data standardization and slice-level metadata creation
# Values for image preprocessing script
preprocessing_cfg:
  image_size: 1024
  voxel_num_thre2d: 100
  voxel_num_thre3d: 1000
  remove_label_ids: []  # No labels to remove in this configuration
  target_label_id: null  # No specific label targeted for instance segmentation
  instance_bbox: True
  yolo_compatible: True

# --- OUTPUT (OVERRIDE DEFAULT): Location to output SAM-compatible .npy files
npy_dir: ${general_data_dir}/npy/SAM

# ------------------ VISUALIZE NPY ------------------
npy_fig_cfg:
  fig_type: 2D_overlay # Options: '2D_overlay', 'gif', ['2D_overlay', 'gif']
  num_figs: 5  # Number of files to randomly select and process
  slice_selection: 'any' # 'any' 'with_segmentation'
# --- OUTPUT (OVERRIDE DEFAULT): location to save figures
  fig_path: ${npy_dir}/figs

# ------------------ INFO FOR METADATA EXTRACTION ------------------
# Original MRI dicom image folder path
mri_dicom_dir: ${image_data_paths}
dicom_column: imgs_dcms

metadata_cfg:
  ## details about your dataset:
  dataset_name: ${dataset.name}
  anatomy: 'shoulder'
  field_strength: '3.0'
  mri_sequence: '3D_CUBE'

  ## MRI dicom header info to extract for statistics metadata:
  dicom_values:
    AccessionNumber: AccessionNumber
    SOPInstanceUID: SOPInstanceUID
    StudyInstanceUID: StudyInstanceUID
    SeriesInstanceUID: SeriesInstanceUID
    series_desc: SeriesDescription
    study_desc: StudyDescription
    TE: EchoTime
    TR: RepetitionTime
    flip_angle: FlipAngle
    ETL: EchoTrainLength
    field_strength: MagneticFieldStrength
    receive_coil: ReceiveCoilName
    scanner_name: StationName
    scanner_model: ManufacturerModelName
    slice_thickness: SliceThickness
    slice_spacing: SpacingBetweenSlices
    pixel_spacing: PixelSpacing
    rows: Rows
    columns: Columns
    # instanceNumber: InstanceNumber  #This was left out??? :,) need for downstream eval
    Age: PatientAge   
    Sex: PatientSex
    Weight: PatientWeight

# Operation A (Optional) 
# Path to a table/dataframe for demographic or other info desired for metadata:
#extra_metadata_cfg:

# Operation B (Optional) 
# JSON dictionary to provide supplementary info (demographics, imaging parameters) - default is our stats file
additional_metadata_file: ${general_data_dir}/metadata/volume_metadata_for_stats.json

# --- OUTPUTS (OVERRIDE DEFAULT): 
# Operation A - location for Statistics slice-level information
stats_metadata_file: ${general_data_dir}/metadata/volume_metadata_for_stats.json
# Operation B - location of subject-level metadata used for training
ml_metadata_file: ${general_data_dir}/metadata/volume_metadata_for_ml.json
# Operation C - location to parquet files for ML
slice_info_parquet_dir: ${general_data_dir}/metadata/SAM/slice_paths   # might not be necessary right now; I really just want the yolo component
# Operation D - location for text file of dicom metadata from one file
dicom_metadata_file: ${general_data_dir}/metadata/dicom_metadata_summary.csv

