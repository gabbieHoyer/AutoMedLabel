## mskSAM Dataset Pre-Processing Parameters
## Params for:
##     1. data_standardization.py: data standardization of input image and mask file
##     2. metadata_extraction.py: standardize metadata for statistics
##     3. sam_prep.py: SAM compatible npy data standardization and slice-level metadata creation
##     4. prompt_prediction.py: extended functionality for choosing prompt experimentation / zeroshot inference


# ------------------ PARAMS FOR ALL ------------------
dataset:
  name: BACPAC_UH2_T1ax
  description: "3.0T T1 Axial lumbar spine dataset with muscle masks."

overwrite_existing_flag: True

# --- OUTPUT (DEFAULT): uses default folder structure when output path is not specified (see load_config())
default_output_dir: /data/mskscratch/users/ghoyer/spine_t1ax_pipeline
general_data_dir: ${default_output_dir}/standardized_spine/BACPAC_UH2/lumbar_spine/T1_ax

# ------------------ INFO FOR DATA STANDARDIZATION ------------------
# Packaged MRI image and mask folder paths (can be dicom or other file type)
image_data_paths:  /data/mskdata/notebooks/BACPAC_UH2/lumbar_spine/T1_ax/Bacpac_mdai_t1ax_dcm_mask_data.csv
mask_data_paths: ${image_data_paths}

image_column: imgs_dcms
mask_column: ['erector_spinae_h5', 'multifidus_h5', 'psoas_h5', 'quadratus_lumborum_h5'] 

image_config:
  key: 
  transforms:
  data_properties:
    finite_values: True

mask_config:
  key: gt
  transforms:
    combination_method: combine_binary_labels
    transpose: [2, 0 ,1]
    dtype: np.uint8
  data_properties:
    finite_values: True
    type: int8
    number_unique_values: 5

## details about your dataset:
mask_labels:
  0: background
  1: muscle_erector_spinae
  2: muscle_multifidus
  3: muscle_psoas
  4: muscle_quadratus_lumborum

# --- OUTPUT (OVERRIDE DEFAULT): location to Output/locate nifti files for MRI images and masks

nifti_image_dir: /data/mskdata/standardized/BACPAC_UH2/lumbar_spine/T1_ax/nifti/imgs
nifti_mask_dir: /data/mskdata/standardized/BACPAC_UH2/lumbar_spine/T1_ax/nifti/masks

# ------------------ VISUALIZE NIFTI ------------------
nifti_fig_cfg:
  fig_type: 2D_overlay # Options: '2D_overlay', 'gif', ['2D_overlay', 'gif']
  num_figs: 1  # Number of files to randomly select and process
  slice_selection: 'with_segmentation' # 'any' 'with_segmentation'
# --- OUTPUT (OVERRIDE DEFAULT): location to save figures
  fig_path: ${general_data_dir}/nifti/figs

# ------------------ INFO FOR SAM PREP ------------------
## SAM compatible npy data standardization and slice-level metadata creation
# Values for image preprocessing script
preprocessing_cfg:
  image_size: 1024
  voxel_num_thre2d: 100
  voxel_num_thre3d: 400
  remove_label_ids: []  # No labels to remove in this configuration
  target_label_id: null  # No specific label targeted for instance segmentation
  instance_bbox: True 
  yolo_compatible: True


# --- OUTPUT (OVERRIDE DEFAULT): Location to output SAM-compatible .npy files
# npy_dir: ${project_data_dir}/npy
npy_dir: ${general_data_dir}/npy/SAM

# ------------------ VISUALIZE NPY ------------------
npy_fig_cfg:
  fig_type: 2D_overlay # Options: '2D_overlay', 'gif', ['2D_overlay', 'gif']
  num_figs: 5  # Number of files to randomly select and process
  slice_selection: 'any' # 'any' 'with_segmentation'
# --- OUTPUT (OVERRIDE DEFAULT): location to save figures
  fig_path: ${npy_dir}/figs

# ------------------ INFO FOR METADATA EXTRACTION ------------------
# Original MRI dicom image folder path
mri_dicom_dir: ${image_data_paths}
dicom_column: imgs_dcms

metadata_cfg:
  ## details about your dataset:
  dataset_name: ${dataset.name}
  anatomy: 'lumbar_spine'
  field_strength: '3.0'
  mri_sequence: 't1_ax'

  ## MRI dicom header info to extract for statistics metadata:
  dicom_values:
    PID: PatientID
    AccessionNumber: AccessionNumber
    SOPInstanceUID: SOPInstanceUID
    StudyInstanceUID: StudyInstanceUID
    SeriesInstanceUID: SeriesInstanceUID
    series_desc: SeriesDescription
    study_desc: StudyDescription
    TE: EchoTime
    TR: RepetitionTime
    flip_angle: FlipAngle
    ETL: EchoTrainLength
    field_strength: MagneticFieldStrength
    receive_coil: ReceiveCoilName
    scanner_name: StationName
    scanner_model: ManufacturerModelName
    slice_thickness: SliceThickness
    slice_spacing: SpacingBetweenSlices
    pixel_spacing: PixelSpacing
    rows: Rows
    columns: Columns
    instanceNumber: InstanceNumber
    Age: PatientAge   # '036Y'
    Sex: PatientSex
    Weight: PatientWeight

# Operation A (Optional) 
# Path to a table/dataframe for demographic or other info desired for metadata:
#extra_metadata_cfg:

# Operation B (Optional) 
# JSON dictionary to provide supplementary info (demographics, imaging parameters) - default is our stats file
additional_metadata_file: ${general_data_dir}/metadata/volume_metadata_for_stats.json

# --- OUTPUTS (OVERRIDE DEFAULT): 
# Operation A - location for Statistics slice-level information
stats_metadata_file: ${general_data_dir}/metadata/volume_metadata_for_stats.json
# Operation B - location of subject-level metadata used for training
ml_metadata_file: ${general_data_dir}/metadata/volume_metadata_for_ml.json
# Operation C - location to parquet files for ML
# slice_info_parquet_dir: ${project_data_dir}/metadata/slice_paths
slice_info_parquet_dir: ${general_data_dir}/metadata/SAM/slice_paths 
# slice_info_parquet_dir: ${project_data_dir}/metadata/SAM2/slice_paths

# Operation D - location for text file of dicom metadata from one file
dicom_metadata_file: ${general_data_dir}/metadata/dicom_metadata_summary.csv


# ------------------ Prompting Experimentation ------------------
prompt_experiment: 
  config: baseline_prompt.yaml


# # ------------------ INFO FOR YOLO PREP ------------------
# ## YOLO compatible npy data standardization, txt label creation
# # Values for image preprocessing script
yolo_preprocessing_cfg:
  image_size: [1024, 1024]
  voxel_num_thre2d: 100
  voxel_num_thre3d: 400
  remove_label_ids: []  
  target_label_id: null  # No specific label targeted for instance segmentation
  instance_bbox: True

yolo_npy_dir: ${general_data_dir}/npy/YOLO